{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/jenkinsnicholas/Documents/personalsite'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_file_details(filename):\n",
    "\n",
    "    details, filetype = filename.split(\".\")\n",
    "\n",
    "    date, major_type, title, tags = details.split(\"_\")\n",
    "\n",
    "    title_cap = title.replace(\"-\",\" \").capitalize()\n",
    "\n",
    "    if tags:\n",
    "        tags = tags.split(\"-\")\n",
    "    else:\n",
    "        tags = []\n",
    "\n",
    "    year, month, day = date.split(\"-\")\n",
    "\n",
    "    if month in [\"01\", \"02\", \"03\", \"04\"]:\n",
    "        period = f\"{year}_early\"\n",
    "    elif month in [\"05\", \"06\", \"07\", \"08\"]:\n",
    "        period = f\"{year}_mid\"\n",
    "    elif month in [\"09\", \"10\", \"11\", \"12\"]:\n",
    "        period = f\"{year}_late\"\n",
    "    else:\n",
    "        period = None\n",
    "\n",
    "    url_helper = f\"{major_type}/{year}/{month}/{day}/{title}\"\n",
    "\n",
    "    article = open_article(filename)\n",
    "\n",
    "    teaser = article[0].replace('â€˜',\"'\").replace('â€™',\"'\")\n",
    "    article = ''.join(article).replace('â€˜',\"'\").replace('â€™',\"'\")\n",
    "\n",
    "    teaser = Markup(markdown.markdown(teaser))        \n",
    "    article = Markup(markdown.markdown(article))\n",
    "    article = article.replace(\"img alt\", \"img class=img-thumbnail alt\")\n",
    "\n",
    "    return {\"filename\": filename, \"date\": date, \"major_type\": major_type, \"title\": title, \"tags\": tags, \"year\": year, \n",
    "            \"month\": month, \"day\": day, \"period\": period, \"filename\": filename, \"filetype\": filetype, \n",
    "            \"title_cap\": title_cap, \"url_helper\": url_helper, \n",
    "            \"teaser\": teaser, \"article\": article}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_article(filename):\n",
    "    with open(os.path.join(\"local\", filename), 'r') as f:\n",
    "        article = f.readlines()\n",
    "    return article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Markup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><code>test</code></p>'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "markdown.markdown(\"```\\n test\\n```\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'filename': '2019-08-18_professional_kevin-bacon-number_analysis-graph-personalprojects.md',\n",
       " 'date': '2019-08-18',\n",
       " 'major_type': 'professional',\n",
       " 'title': 'kevin-bacon-number',\n",
       " 'tags': ['analysis', 'graph', 'personalprojects'],\n",
       " 'year': '2019',\n",
       " 'month': '08',\n",
       " 'day': '18',\n",
       " 'period': '2019_mid',\n",
       " 'filetype': 'md',\n",
       " 'title_cap': 'Kevin bacon number',\n",
       " 'url_helper': 'professional/2019/08/18/kevin-bacon-number',\n",
       " 'teaser': Markup('<p>A long time ago I heard about \\'six degrees of separation\\', and the topic recently came up in a BCG training lecture. We were shown the <a href=\"https://oracleofbacon.org/\">\\'Oracle of Bacon\\'</a> site which shows actor\\'s relationship to Kevin Bacon. I was curious what was the maximum relationship level, so I got to coding. I found this especially interesting as I have recently completed an algorithms course and this looked like a great use case for testing out a breadth-first-search algorithm. I had recently completed another toy project that needed some graphing algorithms so I saw this as a great chance to practice further.</p>'),\n",
       " 'article': Markup('<p>A long time ago I heard about \\'six degrees of separation\\', and the topic recently came up in a BCG training lecture. We were shown the <a href=\"https://oracleofbacon.org/\">\\'Oracle of Bacon\\'</a> site which shows actor\\'s relationship to Kevin Bacon. I was curious what was the maximum relationship level, so I got to coding. I found this especially interesting as I have recently completed an algorithms course and this looked like a great use case for testing out a breadth-first-search algorithm. I had recently completed another toy project that needed some graphing algorithms so I saw this as a great chance to practice further.</p>\\n<p>So, the punchline is that the greatest distance Actor to Kevin Bacon is the infamous <a href=\"https://www.imdb.com/name/nm0755811/\">Iraj Safavi</a> with 10 links. Personally I thought his best acting work was in the 1989 film <a href=\"https://www.imdb.com/title/tt0097843/?ref_=nm_flmg_cin_4\">Homework</a> (I\\'m bullshitting I have no idea who he is). It seems the Iranian film industry is quite isolated from Hollywood (makes sense). Given this linkage is only in terms of co-acting, it makes sense that this number is higher than the \\'six degrees\\' where being an acquaintance is enough.</p>\\n<p>The following is the code used to obtain the results. Be warned that the BFS takes a very long time. The data for the project can be <a href=\"https://oracleofbacon.org/how.php\">found here as JSON</a>.</p>\\n<p>And you can enter Iraj Safavi <a href=\"https://oracleofbacon.org/\">here</a> as an \\'actor\\' link. https://oracleofbacon.org/</p>\\n<p>The following is the code you can use to replicate. BFS uses a linked list, which is commonly a dictionary of str: list indicating actor and co-stars. This was done as a str:set to speed things up.</p>\\n<p>~~~~{.python}\\nimport os\\nimport json\\nfrom collections import defaultdict\\nfrom tqdm import tnrange\\nimport itertools\\nfrom tqdm import tqdm\\nimport pandas as pd\\n~~~~</p>\\n<p>~~~~{.python}</p>\\n<h1>Load data (cant quite straight import)</h1>\\n<p>file = \"data.txt\"</p>\\n<p>data = []\\nwith open(file, \\'r\\') as f:\\n    data = f.readlines()</p>\\n<p>data = [json.loads(d) for d in data]    </p>\\n<p>~~~~</p>\\n<p>~~~~{.python}</p>\\n<h1>Get unique list of actors</h1>\\n<p>all_cast = []</p>\\n<p>for movie in data:\\n    for actor in movie[\"cast\"]:\\n        all_cast.append(actor)</p>\\n<p>all_cast = list(set(all_cast))<br />\\nlen(all_cast)</p>\\n<p>~~~~</p>\\n<p>~~~~{.python}</p>\\n<h1>Get linked list of actor: [worked with, ...]</h1>\\n<h1>Fast method. Not worried about self-duplication</h1>\\n<p>cast_associations = defaultdict(set)</p>\\n<p>for m in tnrange(len(data)):\\n    movie = data[m]</p>\\n<pre><code>for c1 in movie[\"cast\"]:\\n    for c2 in movie[\"cast\"]:\\n        cast_associations[c1].add(c2) # Add both ways\\n        cast_associations[c2].add(c1)\\n</code></pre>\\n<h1>Remove self from cast associations to speed things up</h1>\\n<p>for cast in cast_associations:\\n    cast_associations[cast].remove(cast)\\n~~~~</p>\\n<p>~~~~{.python}</p>\\n<h1>Check Mr Bacon\\'s associations</h1>\\n<p>cast_associations[\"Kevin Bacon\"]</p>\\n<p>```</p>\\n<p>~~~~{.python}</p>\\n<h1>Grabbed a standard breadth first search off stackoverflow</h1>\\n<h1>Credit https://stackoverflow.com/questions/46383493/python-implement-breadth-first-search</h1>\\n<h1>With small modifications</h1>\\n<h1>visits all the nodes of a graph (connected component) using BFS</h1>\\n<p>def bfs_connected_component(graph, start):\\n    # keep track of all visited nodes\\n    explored = []\\n    # keep track of nodes to be checked\\n    queue = [start]</p>\\n<pre><code>levels = {}         # this dict keeps track of levels\\nlevels[start]= 0    # depth of start node is 0\\n\\nvisited= [start]     # to avoid inserting the same node twice into the queue\\n\\n# keep looping until there are nodes still to be checked\\nwith tqdm(total=len(graph)) as pbar: # Added a timing check\\n    while queue:\\n       # pop shallowest node (first node) from queue\\n        node = queue.pop(0)\\n\\n        explored.append(node)\\n        neighbours = graph[node]\\n\\n        # Consider adding a set-&gt;list operation every 10,000 iterations or so to speed up search process\\n\\n\\n        # add neighbours of node to queue\\n        for neighbour in neighbours:\\n            if neighbour not in visited:\\n                queue.append(neighbour)\\n                visited.append(neighbour)\\n                pbar.update(1)\\n\\n                levels[neighbour] = levels[node]+1\\n                # print(neighbour, \"&gt;&gt;\", levels[neighbour])\\nreturn explored, levels\\n</code></pre>\\n<p>~~~~</p>\\n<p>~~~~{.python}\\nexplored, levels = bfs_connected_component(cast_associations, \"Kevin Bacon\")</p>\\n<p>~~~~</p>\\n<p>~~~~{.python}</p>\\n<h1>Print top 10 results</h1>\\n<p>results = pd.DataFrame.from_dict(levels, orient=\\'index\\')[0]\\nresults.name = \"Actor\"\\nresults.tail(10)</p>\\n<h1>results.to_csv(\"bacon_number.csv\")</h1>\\n<p>~~~~</p>')}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myfile = r\"2019-08-18_professional_kevin-bacon-number_analysis-graph-personalprojects.md\"\n",
    "get_file_details(myfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "article = open_article(myfile)\n",
    "\n",
    "# teaser = article[0].replace('â€˜',\"'\").replace('â€™',\"'\")\n",
    "article = ''.join(article).replace('â€˜',\"'\").replace('â€™',\"'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A long time ago I heard about \\'six degrees of separation\\', and the topic recently came up in a BCG training lecture. We were shown the [\\'Oracle of Bacon\\'](https://oracleofbacon.org/) site which shows actor\\'s relationship to Kevin Bacon. I was curious what was the maximum relationship level, so I got to coding. I found this especially interesting as I have recently completed an algorithms course and this looked like a great use case for testing out a breadth-first-search algorithm. I had recently completed another toy project that needed some graphing algorithms so I saw this as a great chance to practice further.\\n\\nSo, the punchline is that the greatest distance Actor to Kevin Bacon is the infamous [Iraj Safavi](https://www.imdb.com/name/nm0755811/) with 10 links. Personally I thought his best acting work was in the 1989 film [Homework](https://www.imdb.com/title/tt0097843/?ref_=nm_flmg_cin_4) (I\\'m bullshitting I have no idea who he is). It seems the Iranian film industry is quite isolated from Hollywood (makes sense). Given this linkage is only in terms of co-acting, it makes sense that this number is higher than the \\'six degrees\\' where being an acquaintance is enough.\\n\\nThe following is the code used to obtain the results. Be warned that the BFS takes a very long time. The data for the project can be [found here as JSON](https://oracleofbacon.org/how.php).\\n\\nAnd you can enter Iraj Safavi [here](https://oracleofbacon.org/) as an \\'actor\\' link. https://oracleofbacon.org/\\n\\nThe following is the code you can use to replicate. BFS uses a linked list, which is commonly a dictionary of str: list indicating actor and co-stars. This was done as a str:set to speed things up.\\n\\n\\n```python\\nimport os\\nimport json\\nfrom collections import defaultdict\\nfrom tqdm import tnrange\\nimport itertools\\nfrom tqdm import tqdm\\nimport pandas as pd\\n```\\n\\n```python\\n# Load data (cant quite straight import)\\nfile = \"data.txt\"\\n\\ndata = []\\nwith open(file, \\'r\\') as f:\\n    data = f.readlines()\\n    \\ndata = [json.loads(d) for d in data]    \\n\\n```\\n\\n\\n```python\\n# Get unique list of actors\\nall_cast = []\\n\\nfor movie in data:\\n    for actor in movie[\"cast\"]:\\n        all_cast.append(actor)\\n        \\nall_cast = list(set(all_cast))  \\nlen(all_cast)\\n\\n```\\n\\n\\n```python\\n# Get linked list of actor: [worked with, ...]\\n# Fast method. Not worried about self-duplication\\ncast_associations = defaultdict(set)\\n\\nfor m in tnrange(len(data)):\\n    movie = data[m]\\n    \\n    for c1 in movie[\"cast\"]:\\n        for c2 in movie[\"cast\"]:\\n            cast_associations[c1].add(c2) # Add both ways\\n            cast_associations[c2].add(c1)\\n            \\n# Remove self from cast associations to speed things up\\nfor cast in cast_associations:\\n    cast_associations[cast].remove(cast)\\n\\n```\\n\\n\\n```python\\n# Check Mr Bacon\\'s associations\\ncast_associations[\"Kevin Bacon\"]\\n\\n```\\n\\n\\n```python\\n# Grabbed a standard breadth first search off stackoverflow\\n# Credit https://stackoverflow.com/questions/46383493/python-implement-breadth-first-search\\n# With small modifications\\n\\n# visits all the nodes of a graph (connected component) using BFS\\ndef bfs_connected_component(graph, start):\\n    # keep track of all visited nodes\\n    explored = []\\n    # keep track of nodes to be checked\\n    queue = [start]\\n\\n    levels = {}         # this dict keeps track of levels\\n    levels[start]= 0    # depth of start node is 0\\n\\n    visited= [start]     # to avoid inserting the same node twice into the queue\\n\\n    # keep looping until there are nodes still to be checked\\n    with tqdm(total=len(graph)) as pbar: # Added a timing check\\n        while queue:\\n           # pop shallowest node (first node) from queue\\n            node = queue.pop(0)\\n            \\n            explored.append(node)\\n            neighbours = graph[node]\\n\\n            # Consider adding a set->list operation every 10,000 iterations or so to speed up search process\\n            \\n            \\n            # add neighbours of node to queue\\n            for neighbour in neighbours:\\n                if neighbour not in visited:\\n                    queue.append(neighbour)\\n                    visited.append(neighbour)\\n                    pbar.update(1)\\n\\n                    levels[neighbour] = levels[node]+1\\n                    # print(neighbour, \">>\", levels[neighbour])\\n    return explored, levels\\n\\n```\\n\\n```python\\nexplored, levels = bfs_connected_component(cast_associations, \"Kevin Bacon\")\\n\\n```\\n\\n```python\\n# Print top 10 results\\nresults = pd.DataFrame.from_dict(levels, orient=\\'index\\')[0]\\nresults.name = \"Actor\"\\nresults.tail(10)\\n\\n#results.to_csv(\"bacon_number.csv\")\\n\\n```\\n'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"\"\"\n",
    "\\n\\n\\n```python\\nimport os\\nimport json\\nfrom collections import defaultdict\\nfrom tqdm import tnrange\\nimport itertools\\nfrom tqdm import tqdm\\nimport pandas as pd\\n```\\n\\n```python\\n# Load data (cant quite straight import)\\nfile = \"data.txt\"\\n\\ndata = []\\nwith open(file, \\'r\\') as f:\\n    data = f.readlines()\\n    \\ndata = [json.loads(d) for d in data]    \\n\\n```\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "test2 = \"\"\"\n",
    "\\n\\n\\n```python\\nimport os\\nimport json\\nfrom collections import defaultdict\\nfrom tqdm import tnrange\\nimport itertools\\nfrom tqdm import tqdm\\nimport pandas as pd\\n```\\n\\n```python\\n# Load data (cant quite straight import)\\nfile = \"data.txt\"\\n\\ndata = []\\nwith open(file, \\'r\\') as f:\\n    data = f.readlines()\\n    \\ndata = [json.loads(d) for d in data]    \\n\\n```\\n\\n\\n```python\\n# Get unique list of actors\\nall_cast = []\\n\\nfor movie in data:\\n    for actor in movie[\"cast\"]:\\n        all_cast.append(actor)\\n        \\nall_cast = list(set(all_cast))  \\nlen(all_cast)\\n\\n```\\n\\n\\n```python\\n# Get linked list of actor: [worked with, ...]\\n# Fast method. Not worried about self-duplication\\ncast_associations = defaultdict(set)\\n\\nfor m in tnrange(len(data)):\\n    movie = data[m]\\n    \\n    for c1 in movie[\"cast\"]:\\n        for c2 in movie[\"cast\"]:\\n            cast_associations[c1].add(c2) # Add both ways\\n            cast_associations[c2].add(c1)\\n            \\n# Remove self from cast associations to speed things up\\nfor cast in cast_associations:\\n    cast_associations[cast].remove(cast)\\n\\n```\\n\\n\\n```python\\n# Check Mr Bacon\\'s associations\\ncast_associations[\"Kevin Bacon\"]\\n\\n```\\n\\n\\n```python\\n# Grabbed a standard breadth first search off stackoverflow\\n# Credit https://stackoverflow.com/questions/46383493/python-implement-breadth-first-search\\n# With small modifications\\n\\n# visits all the nodes of a graph (connected component) using BFS\\ndef bfs_connected_component(graph, start):\\n    # keep track of all visited nodes\\n    explored = []\\n    # keep track of nodes to be checked\\n    queue = [start]\\n\\n    levels = {}         # this dict keeps track of levels\\n    levels[start]= 0    # depth of start node is 0\\n\\n    visited= [start]     # to avoid inserting the same node twice into the queue\\n\\n    # keep looping until there are nodes still to be checked\\n    with tqdm(total=len(graph)) as pbar: # Added a timing check\\n        while queue:\\n           # pop shallowest node (first node) from queue\\n            node = queue.pop(0)\\n            \\n            explored.append(node)\\n            neighbours = graph[node]\\n\\n            # Consider adding a set->list operation every 10,000 iterations or so to speed up search process\\n            \\n            \\n            # add neighbours of node to queue\\n            for neighbour in neighbours:\\n                if neighbour not in visited:\\n                    queue.append(neighbour)\\n                    visited.append(neighbour)\\n                    pbar.update(1)\\n\\n                    levels[neighbour] = levels[node]+1\\n                    # print(neighbour, \">>\", levels[neighbour])\\n    return explored, levels\\n\\n```\\n\\n```python\\nexplored, levels = bfs_connected_component(cast_associations, \"Kevin Bacon\")\\n\\n```\\n\\n```python\\n# Print top 10 results\\nresults = pd.DataFrame.from_dict(levels, orient=\\'index\\')[0]\\nresults.name = \"Actor\"\\nresults.tail(10)\\n\\n#results.to_csv(\"bacon_number.csv\")\\n\\n```\\n'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n\\n\\n\\n```python\\nimport os\\nimport json\\nfrom collections import defaultdict\\nfrom tqdm import tnrange\\nimport itertools\\nfrom tqdm import tqdm\\nimport pandas as pd\\n```\\n\\n```python\\n# Load data (cant quite straight import)\\nfile = \"data.txt\"\\n\\ndata = []\\nwith open(file, \\'r\\') as f:\\n    data = f.readlines()\\n    \\ndata = [json.loads(d) for d in data]    \\n\\n```'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fenced_code' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-41-7aaafc7b9383>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfenced_code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'fenced_code' is not defined"
     ]
    }
   ],
   "source": [
    "fenced_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from markdown.extensions import fenced_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<p><code>python\\ntest</code></p>'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "markdown.markdown(\"```python\\ntest\\n```\", )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'<pre><code class=\"python\">import os\\nimport json\\nfrom collections import defaultdict\\nfrom tqdm import tnrange\\nimport itertools\\nfrom tqdm import tqdm\\nimport pandas as pd\\n</code></pre>\\n\\n<pre><code class=\"python\"># Load data (cant quite straight import)\\nfile = &quot;data.txt&quot;\\n\\ndata = []\\nwith open(file, \\'r\\') as f:\\n    data = f.readlines()\\n\\ndata = [json.loads(d) for d in data]    \\n\\n</code></pre>\\n\\n<pre><code class=\"python\"># Get unique list of actors\\nall_cast = []\\n\\nfor movie in data:\\n    for actor in movie[&quot;cast&quot;]:\\n        all_cast.append(actor)\\n\\nall_cast = list(set(all_cast))  \\nlen(all_cast)\\n\\n</code></pre>\\n\\n<pre><code class=\"python\"># Get linked list of actor: [worked with, ...]\\n# Fast method. Not worried about self-duplication\\ncast_associations = defaultdict(set)\\n\\nfor m in tnrange(len(data)):\\n    movie = data[m]\\n\\n    for c1 in movie[&quot;cast&quot;]:\\n        for c2 in movie[&quot;cast&quot;]:\\n            cast_associations[c1].add(c2) # Add both ways\\n            cast_associations[c2].add(c1)\\n\\n# Remove self from cast associations to speed things up\\nfor cast in cast_associations:\\n    cast_associations[cast].remove(cast)\\n\\n</code></pre>\\n\\n<pre><code class=\"python\"># Check Mr Bacon\\'s associations\\ncast_associations[&quot;Kevin Bacon&quot;]\\n\\n</code></pre>\\n\\n<pre><code class=\"python\"># Grabbed a standard breadth first search off stackoverflow\\n# Credit https://stackoverflow.com/questions/46383493/python-implement-breadth-first-search\\n# With small modifications\\n\\n# visits all the nodes of a graph (connected component) using BFS\\ndef bfs_connected_component(graph, start):\\n    # keep track of all visited nodes\\n    explored = []\\n    # keep track of nodes to be checked\\n    queue = [start]\\n\\n    levels = {}         # this dict keeps track of levels\\n    levels[start]= 0    # depth of start node is 0\\n\\n    visited= [start]     # to avoid inserting the same node twice into the queue\\n\\n    # keep looping until there are nodes still to be checked\\n    with tqdm(total=len(graph)) as pbar: # Added a timing check\\n        while queue:\\n           # pop shallowest node (first node) from queue\\n            node = queue.pop(0)\\n\\n            explored.append(node)\\n            neighbours = graph[node]\\n\\n            # Consider adding a set-&gt;list operation every 10,000 iterations or so to speed up search process\\n\\n\\n            # add neighbours of node to queue\\n            for neighbour in neighbours:\\n                if neighbour not in visited:\\n                    queue.append(neighbour)\\n                    visited.append(neighbour)\\n                    pbar.update(1)\\n\\n                    levels[neighbour] = levels[node]+1\\n                    # print(neighbour, &quot;&gt;&gt;&quot;, levels[neighbour])\\n    return explored, levels\\n\\n</code></pre>\\n\\n<pre><code class=\"python\">explored, levels = bfs_connected_component(cast_associations, &quot;Kevin Bacon&quot;)\\n\\n</code></pre>\\n\\n<pre><code class=\"python\"># Print top 10 results\\nresults = pd.DataFrame.from_dict(levels, orient=\\'index\\')[0]\\nresults.name = &quot;Actor&quot;\\nresults.tail(10)\\n\\n#results.to_csv(&quot;bacon_number.csv&quot;)\\n\\n</code></pre>\\n\\n<p>\\'</p>'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "markdown.markdown(test2, extensions=[\"fenced_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
